{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e240ada3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ffced0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset scifact (/Users/domenicrosati/.cache/huggingface/datasets/scifact/corpus/1.0.0/15660e43ecfb3f7420850027005a63611abb2d401e9746b4059c1260745d9831)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8e3a746bc7f4ae39045dd6c9dbd11cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset scifact (/Users/domenicrosati/.cache/huggingface/datasets/scifact/claims/1.0.0/15660e43ecfb3f7420850027005a63611abb2d401e9746b4059c1260745d9831)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ee4571567dd433fa069bc670a221f0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "corpus = load_dataset('scifact', 'corpus')\n",
    "claims = load_dataset('scifact', 'claims')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c5f1006e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['doc_id', 'title', 'abstract', 'structured'],\n",
       "        num_rows: 5183\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f86fd1cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'claim', 'evidence_doc_id', 'evidence_label', 'evidence_sentences', 'cited_doc_ids'],\n",
       "        num_rows: 1261\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'claim', 'evidence_doc_id', 'evidence_label', 'evidence_sentences', 'cited_doc_ids'],\n",
       "        num_rows: 300\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['id', 'claim', 'evidence_doc_id', 'evidence_label', 'evidence_sentences', 'cited_doc_ids'],\n",
       "        num_rows: 450\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "claims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b88f0e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = claims['train'].to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "01487a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_df = corpus['train'].to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7b89be38",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = df.loc[(df['evidence_label'] == 'CONTRADICT') | (df['evidence_label'] == 'SUPPORT')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ee9d1b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_df['doc_id_str'] = corpus_df['doc_id'].apply(lambda x: str(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "66c31f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, doc in new_df.iterrows():\n",
    "    claim = doc['claim']\n",
    "    evidence = corpus_df[corpus_df['doc_id_str'].apply(lambda x: str(x)) == doc['evidence_doc_id']]['abstract'].iloc[0][doc['evidence_sentences'][0]]\n",
    "    type_ = doc['evidence_label']\n",
    "    score = 1 if type_ == 'CONTRADICT' else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "660da8fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "957\n"
     ]
    }
   ],
   "source": [
    "print(len(new_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5cfab54a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset fever (/Users/domenicrosati/.cache/huggingface/datasets/fever/wiki_pages/1.0.0/366810bbb7a3fa7bdc828fdac879cd1bef00c99b4fe60ba513ab38b1668bf5f0)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "355f2e98573a4cc185f08f584618a41b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wiki_pages = load_dataset('fever', 'wiki_pages')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "659e40b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset fever (/Users/domenicrosati/.cache/huggingface/datasets/fever/v1.0/1.0.0/366810bbb7a3fa7bdc828fdac879cd1bef00c99b4fe60ba513ab38b1668bf5f0)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca2848ab01fe4a9181ddc9a3525696c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fever = load_dataset('fever', 'v1.0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dd725f6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 75397,\n",
       " 'label': 'SUPPORTS',\n",
       " 'claim': 'Nikolaj Coster-Waldau worked with the Fox Broadcasting Company.',\n",
       " 'evidence_annotation_id': 92206,\n",
       " 'evidence_id': 104971,\n",
       " 'evidence_wiki_url': 'Nikolaj_Coster-Waldau',\n",
       " 'evidence_sentence_id': 7}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fever['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "edf9a1cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'Nikolaj_Coster-Waldau' in wiki_pages['wikipedia_pages']['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d1666e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fever_df = fever['train'].to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ab4367a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki_df = wiki_pages['wikipedia_pages'].to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ad449b33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'He then played Detective John Amsterdam in the short-lived Fox television series New Amsterdam -LRB- 2008 -RRB- , as well as appearing as Frank Pike in the 2009 Fox television film Virtuality , originally intended as a pilot .'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiki_df[wiki_df['id'] == 'Nikolaj_Coster-Waldau']['lines'].iloc[0].split('\\n')[7].split('\\t')[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "97794f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "fever_filtered = fever_df[fever_df['evidence_sentence_id'] != -1]\n",
    "fever_filtered = fever_filtered[(fever_filtered['label'] == 'SUPPORTS') | (fever_filtered['label'] == 'REFUTES')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "368c63ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "168293"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(fever_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c8f79cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "91ecebd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset fever (/Users/domenicrosati/.cache/huggingface/datasets/fever/wiki_pages/1.0.0/366810bbb7a3fa7bdc828fdac879cd1bef00c99b4fe60ba513ab38b1668bf5f0)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac3a575a33a0460ea080d1a723d771c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset fever (/Users/domenicrosati/.cache/huggingface/datasets/fever/v1.0/1.0.0/366810bbb7a3fa7bdc828fdac879cd1bef00c99b4fe60ba513ab38b1668bf5f0)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90d41c701d6641f69a040d98351e2606",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wiki_pages = load_dataset('fever', 'wiki_pages')\n",
    "wiki_df = wiki_pages['wikipedia_pages'].to_pandas()\n",
    "fever = load_dataset('fever', 'v1.0')\n",
    "\n",
    "EVIDENCE_LABEL = 'SUPPORTS'\n",
    "\n",
    "fever_df = fever['train'].to_pandas()\n",
    "fever_filtered = fever_df[fever_df['evidence_sentence_id'] != -1]\n",
    "fever_filtered = fever_filtered[(fever_filtered['label'] == 'SUPPORTS') | (fever_filtered['label'] == 'REFUTES')]\n",
    "\n",
    "wiki_df_filtered = wiki_df[wiki_df['id'].isin(fever_filtered['evidence_wiki_url'])]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7415df8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▎       | 39944/168293 [01:05<03:39, 584.47it/s]"
     ]
    }
   ],
   "source": [
    "\n",
    "train_samples = []\n",
    "train_samples_ranking = {}\n",
    "train_df = fever_filtered \n",
    "for i, doc in tqdm(train_df.iterrows(), total=len(train_df)):\n",
    "    try:\n",
    "        claim = doc['claim']\n",
    "        wiki_sentences = wiki_df_filtered[wiki_df_filtered['id'] == doc['evidence_wiki_url']]['lines'].iloc[0].split('\\n')\n",
    "        evidence = wiki_sentences[\n",
    "            doc['evidence_sentence_id']\n",
    "        ].split('\\t')[1]\n",
    "        type_ = doc['label']\n",
    "        score = 1 if type_ == EVIDENCE_LABEL else 0\n",
    "        train_samples.append([claim, evidence, score])\n",
    "        \n",
    "        if claim not in train_samples_ranking:\n",
    "            train_samples_ranking[claim] = {\n",
    "                'query': claim, 'positive': [], 'negative': []\n",
    "            }\n",
    "        \n",
    "        if score == 1:\n",
    "            train_samples_ranking[claim]['positive'].append(evidence)\n",
    "        \n",
    "        train_samples_ranking[claim]['negative'].extend(\n",
    "            sent.split('\\t')[1] for sent in\n",
    "            wiki_df_filtered[wiki_df_filtered['id'] == doc['evidence_wiki_url']]['lines'].iloc[0].split('\\n')\n",
    "            if sent.split('\\t')[1] != evidence and score == 1\n",
    "        )\n",
    "        \n",
    "            \n",
    "        \n",
    "    except Exception as e:\n",
    "        pass\n",
    "    # train_samples.append(InputExample(texts=[claim, evidence], label=score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7657bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_samples_ranking)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "731505b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ranking_samples_filtered = []\n",
    "for sample in list(train_samples_ranking.values()):\n",
    "    if len(sample['positive']) == 0 or len(sample['negative']) == 0:\n",
    "        continue\n",
    "    ranking_samples_filtered.append(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28244d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(ranking_samples_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cadcd94",
   "metadata": {},
   "outputs": [],
   "source": [
    "ranking_samples_filtered[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "350c2fbc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
