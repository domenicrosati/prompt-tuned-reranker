{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "20dc6313",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-10-17 18:37:53 - Use pytorch device: cpu\n",
      "Initializing soft prompt...\n",
      "2022-10-17 18:37:53 - Read scifact train dataset\n",
      "2022-10-17 18:37:54 - Reusing dataset scifact (/Users/domenicrosati/.cache/huggingface/datasets/scifact/corpus/1.0.0/15660e43ecfb3f7420850027005a63611abb2d401e9746b4059c1260745d9831)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11b108c93e9c43ee8f1db3f5c7f39783",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-10-17 18:37:55 - Reusing dataset scifact (/Users/domenicrosati/.cache/huggingface/datasets/scifact/claims/1.0.0/15660e43ecfb3f7420850027005a63611abb2d401e9746b4059c1260745d9831)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8cb9315a4b9d4ea5b2039fe8173ebf88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "This examples trains a CrossEncoder for the STSbenchmark task. A CrossEncoder takes a sentence pair\n",
    "as input and outputs a label. Here, it output a continious labels 0...1 to indicate the similarity between the input pair.\n",
    "\n",
    "It does NOT produce a sentence embedding and does NOT work for individual sentences.\n",
    "\n",
    "Usage:\n",
    "python training_stsbenchmark.py\n",
    "\"\"\"\n",
    "from torch.utils.data import DataLoader\n",
    "import math\n",
    "from sentence_transformers import LoggingHandler, util\n",
    "from sentence_transformers.cross_encoder import CrossEncoder\n",
    "from sentence_transformers.cross_encoder.evaluation import CECorrelationEvaluator\n",
    "from sentence_transformers import InputExample\n",
    "import logging\n",
    "from datetime import datetime\n",
    "from datasets import load_dataset\n",
    "from softprompt_crossencoder import PromptTunedCrossEncoder\n",
    "\n",
    "#### Just some code to print debug information to stdout\n",
    "logging.basicConfig(format='%(asctime)s - %(message)s',\n",
    "                    datefmt='%Y-%m-%d %H:%M:%S',\n",
    "                    level=logging.INFO,\n",
    "                    handlers=[LoggingHandler()])\n",
    "logger = logging.getLogger(__name__)\n",
    "#### /print debug information to stdout\n",
    "\n",
    "\n",
    "EVIDENCE_LABEL = 'CONTRADICT'\n",
    "\n",
    "# #Define our Cross-Encoder\n",
    "train_batch_size = 16\n",
    "num_epochs = 4\n",
    "model_save_path = f'output/ce-{EVIDENCE_LABEL}'\n",
    "\n",
    "#We use cross-encoder/ms-marco-MiniLM-L-12-v2 as base model and set num_labels=1, which predicts a continous score between 0 and 1\n",
    "model = PromptTunedCrossEncoder('cross-encoder/ms-marco-MiniLM-L-12-v2', num_labels=1)\n",
    "\n",
    "\n",
    "# Read scifact dataset\n",
    "logger.info(\"Read scifact train dataset\")\n",
    "corpus = load_dataset('scifact', 'corpus')\n",
    "claims = load_dataset('scifact', 'claims')\n",
    "\n",
    "\n",
    "corpus_df = corpus['train'].to_pandas()\n",
    "corpus_df['doc_id_str'] = corpus_df['doc_id'].apply(lambda x: str(x))\n",
    "\n",
    "train_samples = []\n",
    "train_df = claims['train'].to_pandas()\n",
    "train_df = train_df.loc[(train_df['evidence_label'] == 'CONTRADICT') | (train_df['evidence_label'] == 'SUPPORT')]\n",
    "for i, doc in train_df.iterrows():\n",
    "    claim = doc['claim']\n",
    "    evidence = corpus_df[corpus_df['doc_id_str'].apply(lambda x: str(x)) == doc['evidence_doc_id']]['abstract'].iloc[0][doc['evidence_sentences'][0]]\n",
    "    type_ = doc['evidence_label']\n",
    "    score = 1 if type_ == EVIDENCE_LABEL else 0\n",
    "    train_samples.append(InputExample(texts=[claim, evidence], label=score))\n",
    "\n",
    "dev_samples = []\n",
    "dev_df = claims['validation'].to_pandas()\n",
    "dev_df = dev_df.loc[(dev_df['evidence_label'] == 'CONTRADICT') | (dev_df['evidence_label'] == 'SUPPORT')]\n",
    "for i, doc in dev_df.iterrows():\n",
    "    claim = doc['claim']\n",
    "    evidence = corpus_df[corpus_df['doc_id_str'].apply(lambda x: str(x)) == doc['evidence_doc_id']]['abstract'].iloc[0][doc['evidence_sentences'][0]]\n",
    "    type_ = doc['evidence_label']\n",
    "    score = 1 if type_ == EVIDENCE_LABEL else 0\n",
    "    dev_samples.append(InputExample(texts=[claim, evidence], label=score))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fc1f09ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.0177, -0.0030, -0.0131,  ...,  0.0339, -0.0048,  0.0278],\n",
       "        [-0.0145, -0.0273,  0.0435,  ..., -0.0140,  0.0118, -0.0067],\n",
       "        [-0.0159, -0.0098,  0.0285,  ..., -0.0207,  0.0194, -0.0070],\n",
       "        ...,\n",
       "        [-0.0286, -0.0096,  0.0198,  ..., -0.0143,  0.0192,  0.0015],\n",
       "        [-0.0200, -0.0352,  0.0410,  ..., -0.0092,  0.0259, -0.0069],\n",
       "        [-0.0332, -0.0179,  0.0151,  ..., -0.0184,  0.0263, -0.0073]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.model.soft_prompt.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6809fcdf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "587b8139",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([  101,  1996,  3899,  2003, 21392,  2075,   102]), 'token_type_ids': [0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "34b5fa1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0795db48",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "343a3fa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 4540475.5\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d09ea452",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import (\n",
    "    AdamW,\n",
    "    get_scheduler\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d11f11a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    # Same default parameters as run_clm_no_trainer.py in tranformers\n",
    "    # https://github.com/huggingface/transformers/blob/master/examples/pytorch/language-modeling/run_clm_no_trainer.py\n",
    "    num_train_epochs = 3\n",
    "    weight_decay = 0.01\n",
    "    learning_rate = 0.01\n",
    "    lr_scheduler_type = \"linear\"\n",
    "    num_warmup_steps = 0\n",
    "    max_train_steps = num_train_epochs\n",
    "    \n",
    "    # Prompt-tuning\n",
    "    # number of prompt tokens\n",
    "    n_prompt_tokens = 20\n",
    "    # If True, soft prompt will be initialized from vocab \n",
    "    # Otherwise, you can set `random_range` to initialize by randomization.\n",
    "    init_from_vocab = True\n",
    "    # random_range = 0.5\n",
    "args = Config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5483510a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/domenicrosati/.asdf/installs/python/3.10.4/lib/python3.10/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "optimizer_grouped_parameters = [\n",
    "    {\n",
    "        \"params\": [p for n, p in model.model.named_parameters() if n == \"soft_prompt.weight\"],\n",
    "        \"weight_decay\": args.weight_decay,\n",
    "    }\n",
    "]\n",
    "optimizer = AdamW(optimizer_grouped_parameters, lr=args.learning_rate)\n",
    "lr_scheduler = get_scheduler(\n",
    "    name=args.lr_scheduler_type,\n",
    "    optimizer=optimizer,\n",
    "    num_warmup_steps=args.num_warmup_steps,\n",
    "    num_training_steps=args.max_train_steps,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "dae25590",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 10269.396484375\n"
     ]
    }
   ],
   "source": [
    "inputs = model.tokenizer(\"The dog is peeing\", \"The dog is urinating\")\n",
    "import torch\n",
    "inputs['input_ids'] = torch.tensor(inputs['input_ids'])\n",
    "outputs = model.forward(input_ids=inputs[\"input_ids\"], labels=torch.Tensor([1]))\n",
    "loss = outputs.loss\n",
    "print(f\"loss: {loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ef62c6e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SequenceClassifierOutput(loss=tensor(10269.3965, grad_fn=<MseLossBackward0>), logits=tensor([[1.8434]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4a79750c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  101,  1996,  3899,  2003, 21392,  2075,   102,  1996,  3899,  2003,\n",
       "        24471, 19185,   102])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs['input_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "bf184d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.to(torch.float32).backward()\n",
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "3f1424a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 384])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.model.soft_prompt.weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "4a673760",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(30522, 384, padding_idx=0)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.model.bert.embeddings.word_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ea4bdd29",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.functional import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "6ae600e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30522"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "0ed5f76a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3899)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(model.tokenizer.vocab['dog'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "eb056f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = model.model.bert.embeddings.word_embeddings\n",
    "ans = []\n",
    "for i in range(model.model.bert.embeddings.word_embeddings.num_embeddings):\n",
    "    similarity = torch.cosine_similarity(embeddings(torch.tensor(model.tokenizer.vocab['dog'])).view(1,-1), \n",
    "                                          embeddings(torch.tensor(i)).view(1,-1)).item()\n",
    "    ans.append(similarity)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "6f13bc07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "ind = np.argpartition(ans, -4)[-4:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "201cda2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 4937, 17022,  3899,  6077])"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "165df94b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cat', 'puppy', 'dog', 'dogs']"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.tokenizer.convert_ids_to_tokens(torch.tensor([ 4937, 17022,  3899,  6077]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b3bd75c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dist = model.tokenizer.vocab['dog']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
